{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 314. Оптимальная константа 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Успешно пройдя все этапы отбора, Кеша осуществил свою заветную мечту и попал на стажировку в свою любимую IT-компанию. Так как Кеша отлично показал себя при прохождении секций, руководитель доверил ему сложную исследовательскую задачу: с помощью машинного обучения решить важную проблему бизнеса - повышение счастья новых пользователей сервиса, который развивает команда Кеши.\n",
    "\n",
    "Желая сделать этот мир лучше, наш герой с головой погрузился в продуктовую составляющую задачи, сформулировал ее в терминах машинного обучения и довольно быстро смог построить пайплайн для обучения моделей. Дело за малым: осталось внедрить модель в систему realtime-обработки запросов и вырастить самую главную метрику - счастье пользователей сервиса. Однако, разработчик, который должен был помогать Кеше дотаскивать необходимые для его модели признаки до обработчика запросов, внезапно заболел. Так как Кеша очень ответственный и ему не терпится внедрить свою модель, он нашел временный выход из ситуации - попробовать в качестве прогноза использовать модель без фичей, то есть выдающую на все запросы константный прогноз.\n",
    "\n",
    "Единственная трудность заключается в том, что показатель «счастье пользователей», за улучшение которого борется Кеша, является сложноизмеримой величиной, которую пока никто не смог записать в виде простой аналитической формулы. Как вдумчивый исследователь, Кеша хочет попробовать несколько разных метрик качества, для каждой из них получить оптимальное значение константы и затем промерить полученные константы в онлайн эксперименте, дабы определить, какая из них лучше растит счастье.\n",
    "\n",
    "Перед выкаткой эксперимента в онлайн, Кеша обратился к вам, как к своему потенциальному коллеге, чтобы вы помогли ему провалидировать результаты. Помогите Кеше максимизировать всеобщее счастье!\n",
    "\n",
    "Для вашего удобства Кеша уже сделал предварительную обработку данных и подготовил обучающую выборку. Решается задача регрессии, в которой целевая функция имеет вид $t_i = \\frac{b_i}{a_i}$, где $a_i$ и $b_i$ - некоторые статистики, влияющие на счастье пользователя. Кеша знаком с техникой перевзвешивания и активно ее использует для решения задачи: каждому объекту обучающей выборки приписывается некоторый вес, который отвечает за \"важность\" данного объекта (чем больше вес, тем сильнее модель при обучении штрафуется за отклонение предсказания от значения целевой функции на данном объекте). При целевой переменной указанного вида зачастую бывает разумно для повышения устойчивости модели в качестве веса использовать $w_i = b_i$, что и делает Кеша. Таким образом, обучающая выборка - это набор из $n$ объектов, представляющих собой тройки $(x_i,a_i,b_i)$, где $x_i$ - признаковое описание объекта, то есть вектор вещественных чисел длиной $k$ (важно помнить, что признаки не будут использоваться при применении в продакшене), $a_i$ и $b_i$ - статистики, необходимые для вычисления целевой функции $t_i$ и веса $w_i$.\n",
    "\n",
    "Пусть $p$ - прогноз модели, которую обучает Кеша. Тогда используемые в нашей задаче метрики качества можно записать следующим образом:\n",
    "\n",
    "**Mean squared error:**\n",
    "\n",
    "$MSE=\\frac{\\sum w_i*(t_i-p)^2}{\\sum w_i}$\n",
    "\n",
    "**Mean squared logarithmic error:**\n",
    "\n",
    "$MSLE=\\frac{\\sum w_i*(ln(1+t_i)-ln(1+p))^2}{\\sum w_i}$\n",
    "\n",
    "**Logistic loss:**\n",
    "\n",
    "$LogLoss=\\frac{\\sum w_i*[\\frac{t_i}{C}ln(\\frac{p}{C})-(1-\\frac{t_i}{C})ln(1-\\frac{p}{C})]}{\\sum w_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое простое решение:\n",
    "1. Взять производные\n",
    "2. Приравнять к 0 \n",
    "3. Найти p\n",
    "\n",
    "**Производная по $MSE$:**\n",
    "\n",
    "$p = \\frac{\\sum w_i*t_i}{\\sum w_i}$\n",
    "\n",
    "**Производная по $MSLE$:**\n",
    "\n",
    "$p = exp(\\frac{\\sum w_i*ln(1+t_i)}{\\sum w_i})-1$\n",
    "\n",
    "**Производная по $LogLoss$:**\n",
    "\n",
    "$p*\\sum w_i*t_i - C*\\sum w_i*t_i + p*\\sum w_i - p*\\sum w_i*t_i = 0$\n",
    "\n",
    "Отсюда, выражаем $p$:\n",
    "\n",
    "$p = \\frac{\\sum w_i*t_i}{\\sum w_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "n, k = list(map(int, input().split()))\n",
    "arr = np.array([list(map(float, input().split())) for i in range(n)])\n",
    "\n",
    "a = arr[:,-2]\n",
    "b = arr[:,-1]\n",
    "w = arr[:,-1]\n",
    "t = a/b\n",
    "\n",
    "p1 = sum(w*t)/sum(w)\n",
    "p2 = np.exp(sum(w*np.log(1+t))/sum(w))-1\n",
    "p3 = sum(w*t)/sum(w)\n",
    "\n",
    "print(p1, p2, p3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
